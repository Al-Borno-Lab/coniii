\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{CONIII: Convenient Interface to Inverse Ising}
\author{Edward D Lee, Bryan C Daniels, Colin Twomey, Colin Clement}
%\date{}                                           % Activate to display a given date or no date

\newcommand{\br}[1]{\left<#1\right>}
\newcommand{\si}[0]{\sigma_{\rm i}}
\newcommand{\sj}[0]{\sigma_{\rm j}}

\begin{document}
\begin{abstract}
CONIII is a project for providing a simple interface to various algorithms for solving the inverse maximum entropy problem. In this guide, we provide details sufficient for graduate students who are new to this area to understand how the algorithms work and plug-and-play code to run them on their data sets. We hope that this interface will provide the means for maximum entropy modeling techniques to become more widespread and provide a platform for organizing the various techniques into a convenient environment.
\end{abstract}

\maketitle

\section{Introduction}
Many biological systems are characterized by collective behavior whether it is the correlated pattern of neuron firing, protein diversity in the immune system, conflict participation in monkeys, or consensus voting in the US Supreme Court. Statistical physics is a natural approach to probing such systems precisely because they are collective.
Recently, with the advent of numerical, analytic, and computation tools, it has become possible to solve for the statistical physics model that corresponds to a particular system, an approach known as the inverse problem.
This is in contrast with the typical problem in statistical physics where one postulates the Hamiltonian and works out the physical behavior of the system. In the \textit{inverse} problem, we  find the parameters that correspond to observed behavior of a known system. In many cases, this is a very difficult problem to solve and does not have an analytical solution, and we must rely on analytic approximation and numerical techniques to estimate the parameters.

There are a variety of techniques for approaching the inverse problem|often in context of a particular model|but they are often presented as different approaches without clear relations to one another. Instead of focusing on the details of each technique separately, we relate these techniques to one another and point out when one would fail or be difficult to apply.

We hope to provide a (soft) introduction to the analytic, numerical, and computational techniques used to solve these problems to make them accessible to students especially at the graduate level (and even advanced undergraduates). With the goal of furthering general understanding, we aim not to be rigorous but to be accurate and comprehensible, pointing to the relevant literature whenever possible. Although we strive to be as clear and explicit as possible across this guide, a good background in mathematics or physics will be extremely helpful. In some places, we have left out steps in the derivations, and we encourage the reader to work out the missing steps.

\section{Why maximum entropy?}
The inverse problem is typically formulated as constrained optimization problem, where the objective is to fit to particular aspects of the data while maximizing the entropy of the statistical model. This approach is equivalent minimizing the free energy as we typically do in statistical physics. This is equivalent to a constrained optimization problem while maximizing the entropy.

The idea behind maximum entropy, or maxent, is to build a model that is consistent with the data but otherwise as structureless as possible. Maximizing the entropy $S[p] = -\sum p_i \log p_i$ while fitting $K$ constraints indexed by $k$, $\sum_i p_i f_k(\sigma_i)$ can be solved by the method of Langrangian multipliers
\begin{align}
	-\ln Z &= -\sum_i p_i\log p_i - \sum_k \lambda_k \sum_i p_i f_k(\sigma_i)\\
	F &= S - \br{E}
\end{align}
The notation draw out the equivalence between maximizing entropy and minimizing the Helmholtz free energy of system. By specifying the constraints on the maximization, we fix the form of the Hamiltonian. This formulation makes clear the fundamental connection between the maximum entropy principle and statistical mechanics \cite{Jaynes}.

The resulting model is a Boltzmann distribution over states
\begin{align}
	p(\sigma) &= e^{-E(\sigma)}/Z\\
	Z &= \sum_\sigma e^{-E(\sigma)}
\end{align}

A well known example is that of the Ising model with binary spins $\sigma_{\rm i} \in {-1,1}$ with Hamiltonian 
\begin{align}
	E &= -\sum_{\br{\rm ij}} J_{\rm ij}\si\sj -\sum_{\rm i=1}^N h_i\si
\end{align}
with couplings $J_{\rm ij}$ between neighbors and external fields specific to each spin $h_{\rm i}$. The Ising model can be obtained from insisting that the magnetizations and pairwise correlations of the model match those observed in the data
\begin{align}
	\br{\si}_{\rm obs} &= \br{\si}\\
	\br{\si\sj}_{\rm obs} &= \br{\si\sj}
\end{align}

Enforcing the constraints is equivalent to minimizing the Kullback-Leibler divergence between the model and the data
\begin{align}
	D_{KL}(p||q) &= \sum p_k \log\left(\frac{p_k}{q_k}\right)\\
	\frac{\partial D}{\partial \lambda_k} &= p_k \frac{\partial (-E-Z)}{\partial \lambda_k}\\
	0 &= \br{f_k}_{\rm obs} -\br{f_k}
\end{align}
[Of course, we also have to show that the problem is convex.]

\section{Mean-field methods}
[I'm imagining that we neatly tie together the different techniques. As far as I know, they're all different approaches and no one's done a real good job relating one technique to another. It's easy enough to go read a bunch of different papers about each method, but it's not so clear why one is preferable over another.]

Analytic approximations simplify the equations to an extent where they are tractable.

\section{Monte Carlo methods}
Perhaps the most direct route to solving these equations is to use Monte Carlo sampling to approximate the distribution and guess how to adjust the parameters appropriately.

Monte Carlo sampling is...

This can be combined with a variety of more sophisticated stochastic gradient descent ideas to solve the problem.

\subsection{Monte Carlo histogram}
Since the sampling step is expensive, could we reuse a sample for more than one gradient descent step? This is the idea behind Monte Carlo histogram. Instead of sampling every time we change the parameters, we can predict how the distribution will change \textit{if} we modify the parameters slightly. Given that we have a sample,
\begin{align}
	q(\sigma) &= \frac{q(\sigma)}{p(\sigma)}p(\sigma)\\
		&= \frac{Z'}{Z}e^{\epsilon\sum_k \lambda_k \epsilon f_k} p\\
\intertext{but we have a sampled approximation to $p$. By summing over all states}
	\br{f_k}' &= \frac{Z'}{Z} \br{e^{\epsilon\sum_k \lambda_k f_k} f_k}_{\rm obs}
\end{align}

\section{Pseudolikelihood}

\section{Minimum Probability Flow}

\section{Cluster expansions}

\section{Bethe/Kikuchi free energy}

\section{CONIII}

\subsection{How to validate a maxent model}
The hope of maxent is that by fixing some aspects of the probability distribution, we can forget about the rest. In this sense, maxent is not a typical fitting method where the optimal parameters are sought such that the model is as good as possible. Instead, we specify which aspects of the system we think are important and the resulting ``parameters'' come from the maximum entropy principle.

Thus, one way to test the model is to consider how well we do in predicting the rest of the distribution. If the rest of the distribution is not well fit, certainly we must go back and reconsider which constraints to impose. On the other hand, finding that the rest of the probability distribution is fit is all good and well, but it does not necessarily mean we have found the right model [cite much discussion here].

\section{Criticality in biological systems}

\section{Why not maximum entropy?}

\section{Notes on Monte Carlo Markov Chain sampling}
The key points behind MCMC sampling is ergodicity and detailed balance. Ergodicity just means that we can get from one state to another in a finite number of steps, and this ensures that we don't get stuck in a few states. Detailed balance is a sufficient but not necessary condition (stronger than needed) for ensuring that the equilibrium distribution matches the distribution that we seek. There are some specialized algorithms that don't satisfy detailed balance but do produce the desired distribution.

To check whether an algorithm works, one must prove that both these conditions are satisfied. Ergodicity is usually trivial. Typically, we write down the condition for detailed balance for any two states $a$ and $b$,
\begin{align}
	p(a|b)p(b) &= p(b|a)p(a) \\
	p(b)/p(a) &= p(b|a)/p(a|b) \\
	e^{-(E_b-E_a)} &= 
\end{align}
A reasonable way to do this would be to take $p(b|a) = e^{-(E_b-E_a)}$ and $p(a|b) = 1$ when $E_b>E_a$.

\begin{align}
	p_a\,T(a\rightarrow b)A(a\rightarrow b) &= p_b\,T(b\rightarrow a)A(b\rightarrow a)\\
	p_a/p_b &= T(b\rightarrow a)A(b\rightarrow a)/T(a\rightarrow b)A(a\rightarrow b)
\end{align}
where $T$ is the transition probability and $A$ is the acceptance probability. For a Boltzmann type model, this means that this ratio must be equal to $\exp(-\beta(E_a-E_b))$.

\subsection{Swendsen-Wang}
As an example, we consider the Swendsen-Wang cluster algorithm. In this algorithm, the first step is to form bonds between like spins (to grow clusters) then we flip to any configuration permitted by the current bond structure which is uniform. If you work through the calculations (GNB V pg 81), you will find that the probability of transitioning between states depend on the bonds that could have formed between like spins but didn't, and this is equal to the energy difference between the states.

\subsection{Wolff}
Another example is the Wolff algorithm (see GNB V pg 83) which is like the SW algorithm except that only a single cluster is build and flipped at a time with probability 1, i.e. the acceptance probability is 1 in the original algorithm. We start with any random site as the initial spin then we build a cluster spreading out from that spin to its nearest neighbors where the choose the probability of choosing a neighbor to be $1-\exp(-2J_{ij})$.

The random fields can be accounted for in the acceptance probabilities (so the probability of a cluster flipping is no longer 1). Working through the math, you will find that the cluster growth accounts for the ratio of the energies that come from the couplings but to account for the fields, the probability of a particular orientation of the clusters has to be
\begin{align}
	p(\Sigma_n) &\propto \exp\left(\sum_i h_i\sigma_i\right)
\end{align}
which we can easily simulate using something like the Metropolis algorithm. Obviously, this will increase the correlation time between samples because we will not always accept a cluster flip. This can be especially problematic when the clusters become large and have similar fields, but as long as the sum of the distribution of local fields for spins in a cluster is symmetric about 0, this will not be too slow. Certainly, it is faster than any local flip algorithm.

A simple example that I worked through is with 4 spins and the transition probability between two different states. Here, we can easily enumerate all possible ways of transitioning between these two states using the Wolff algorithm.

\section{Replica exchange Monte Carlo (REMC)}
REMC simulates multiple replicas of the system at different temperatures simulaneously and allow states to be exchanged between them. The idea is that an energy barrier may be very difficult to cross below a certain critical temperature, but there may be a trajectory allowed by diffusing through higher temperatures to cross the boundary.

Instead of considering the ensemble of a single system, we consider the ensemble of multiple independent systems. Thus, the joint probability distribution on the extended state space is
\begin{align}
	p(\sigma,\beta_n).
\end{align}
where $\beta_n = 1/T_n$ is the inverse temperature.

The simplest possible assumption for the shape of this distribution would be that the probability of occupying any particular temperature $\beta_n$ is uniform $p(n) = 1/N_T$. It turns out that this is optimal according to some criterion (see citation in Kerler and Rehberg). Note that this is not the same as just simulating a set of replicas for which the partition funtion would be
\begin{align}
	Z &= \prod_{m} \sum_\sigma \exp\left[ -\beta_m H(\sigma) \right] \label{eq:equi Z}
\end{align}
This is for the obvious reason that the average energy is a function of $T$ so a simulation of Eq \ref{eq:equi Z} would spend much more time exploring lower temperatures than higher temperatures. This makes it difficult to have the system use higher energy states to cross energy barriers. 

So instead of Eq \ref{eq:equi Z}, we can include a term $g_n$ to compensate
\begin{align}
	Z &= \prod_{m} \sum_\sigma \exp\left[ -\beta_m H(\sigma) +g_m \right]
\end{align}
How do we find $g_n$?

Under the assumption that the probability $p(n)$ is a constant,
\begin{align}
	p(n) &= e^{g_n} \sum_\sigma \exp\left[ -\beta_n H(\sigma) \right]/Z\\
	g_n &= \log[p(n)\,Z] + \tilde{Z}_n\\
	g_n &\rightarrow \tilde{Z}_n
\end{align}
(remembering that constants don't matter in the relation between energy and probability) where 
\begin{align}
	\tilde{Z}_n &= \sum_\sigma \exp\left[ -\beta_n H(\sigma) \right]
\end{align}
One way to find the $g_n$ that satisfy this condition is to come up with an iterative algorithm that converges to a fixed point. One suggestion is to estimate $g_n$ by reweighting the distributions from adjacent replicas.

Now, it remains to find a set of $\beta_n$ that is optimal for simulating relaxing into equilibrium quickly. One suggestion to make the algorithm spend an equal amount of time at each temperature. Kerler and Rehberg suggest a method.

\end{document}  