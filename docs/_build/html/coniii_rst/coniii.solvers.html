<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>coniii.solvers module &#8212; ConIII 1.0.2 documentation</title>
    
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.0.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="ConIII 1.0.2 documentation" href="../index.html" />
    <link rel="next" title="coniii.samplers module" href="coniii.samplers.html" />
    <link rel="prev" title="Welcome to ConIII’s documentation!" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-coniii.solvers">
<span id="coniii-solvers-module"></span><h1>coniii.solvers module<a class="headerlink" href="#module-coniii.solvers" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="coniii.solvers.ClusterExpansion">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">ClusterExpansion</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Implementation of Adaptive Cluster Expansion for solving the inverse Ising problem, as
described in John Barton and Simona Cocco, J. of Stat. Mech.  P03002 (2013).</p>
<p>Specific to pairwise Ising constraints.</p>
<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.S">
<code class="descname">S</code><span class="sig-paren">(</span><em>cluster</em>, <em>coocMat</em>, <em>deltaJdict={}</em>, <em>useAnalyticResults=False</em>, <em>priorLmbda=0.0</em>, <em>numSamples=None</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.S" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate pairwise entropy of cluster.
(First fits pairwise Ising model.)</p>
<dl class="docutils">
<dt>useAnalyticResults</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,False</span><dd>Probably want False until analytic formulas are changed to include prior on J</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.Sindependent">
<code class="descname">Sindependent</code><span class="sig-paren">(</span><em>cluster</em>, <em>coocMat</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.Sindependent" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.clusterID">
<code class="descname">clusterID</code><span class="sig-paren">(</span><em>cluster</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.clusterID" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.deltaS">
<code class="descname">deltaS</code><span class="sig-paren">(</span><em>cluster</em>, <em>coocMat</em>, <em>deltaSdict=None</em>, <em>deltaJdict=None</em>, <em>verbose=True</em>, <em>meanFieldRef=False</em>, <em>priorLmbda=0.0</em>, <em>numSamples=None</em>, <em>independentRef=False</em>, <em>meanFieldPriorLmbda=None</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.deltaS" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>cluster</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list </span><dd>List of indices in cluster</dd>
<dt>independentRef</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,False</span><dd>If True, expand about independent entropy</dd>
<dt>meanFieldRef</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,False</span><dd>If True, expand about mean field entropy</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>X</em>, <em>threshold</em>, <em>cluster=None</em>, <em>deltaSdict=None</em>, <em>deltaJdict=None</em>, <em>verbose=True</em>, <em>priorLmbda=0.0</em>, <em>numSamples=None</em>, <em>meanFieldRef=False</em>, <em>independentRef=True</em>, <em>veryVerbose=False</em>, <em>meanFieldPriorLmbda=None</em>, <em>return_all=False</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.solve" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>X</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">array-like</span><dd>Data set (n_samples,n_dim).</dd>
</dl>
<p>threshold : float
meanFieldRef : bool,False</p>
<blockquote>
<div>Expand about mean-field reference</div></blockquote>
<dl class="docutils">
<dt>independentRef</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,True</span><dd>Expand about independent reference</dd>
<dt>priorLmbda</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float,0.</span><dd>Strength of non-interacting prior</dd>
<dt>meanFieldPriorLmbda</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float,None</span><dd>Strength of non-interacting prior in mean field calculation
(defaults to priorLmbda)</dd>
</dl>
<dl class="docutils">
<dt>With return_all=False, returns</dt>
<dd>J           : Estimated interaction matrix</dd>
<dt>With return_all=True, returns</dt>
<dd>ent         : Estimated entropy
J           : Estimated interaction matrix
clusters    : List of clusters
deltaSdict  : 
deltaJdict  :</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.ClusterExpansion.subsets">
<code class="descname">subsets</code><span class="sig-paren">(</span><em>set</em>, <em>size</em>, <em>sort=False</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.ClusterExpansion.subsets" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list, returns a list of all unique subsets
of that list with given size.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.Enumerate">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">Enumerate</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Enumerate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving +/-1 symmetric Ising model maxent problems by gradient descent with flexibility to put
in arbitrary constraints.</p>
<dl class="method">
<dt id="coniii.solvers.Enumerate.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>constraints=None</em>, <em>samples=None</em>, <em>initial_guess=None</em>, <em>max_param_value=50</em>, <em>fsolve_kwargs={'method': 'powell'}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Enumerate.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>constraints : ndarray
samples : ndarray</p>
<blockquote>
<div>(n_samples, n_dim)</div></blockquote>
<dl class="docutils">
<dt>initial_guess</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray,None</span><dd>initial starting point</dd>
<dt>fsolve_kwargs</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">dict,{&#8216;method&#8217;:&#8217;powell&#8217;}</span><dd>Powell method is slower but tends to converge better.</dd>
</dl>
<p>Tuple of solved parameters and output from scipy.optimize.minimize</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.MCH">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">MCH</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Class for solving maxent problems using the Monte Carlo Histogram method.</p>
<p>Broderick, T., Dudik, M., Tkacik, G., Schapire, R. E. &amp; Bialek, W. Faster solutions of the
inverse pairwise Ising problem. arXiv 1-8 (2007).</p>
<p>constraints : ndarray
calc_observables (function)</p>
<blockquote>
<div>takes in samples as argument</div></blockquote>
<dl class="docutils">
<dt>calc_e (function)</dt>
<dd>with args (sample,parameters) where sample is 2d</dd>
</dl>
<p>mch_approximation (function)
sampleSize : int
multipliers : ndarray</p>
<blockquote>
<div>set the Langrangian multipliers</div></blockquote>
<dl class="method">
<dt id="coniii.solvers.MCH.estimate_jac">
<code class="descname">estimate_jac</code><span class="sig-paren">(</span><em>eps=0.001</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.estimate_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximation Jacobian using the MCH approximation.</p>
<p>eps : float,1e-3</p>
<dl class="docutils">
<dt>jac</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>Jacobian is an n x n matrix where each row corresponds to the behavior of fvec wrt to a
single parameter.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MCH.learn_parameters_mch">
<code class="descname">learn_parameters_mch</code><span class="sig-paren">(</span><em>estConstraints</em>, <em>maxdlamda=1</em>, <em>maxdlamdaNorm=1</em>, <em>maxLearningSteps=50</em>, <em>eta=1</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.learn_parameters_mch" title="Permalink to this definition">¶</a></dt>
<dd><p>estConstraints : ndarray
maxdlamda : float,1
maxdlamdaNorm : float,1
maxLearningSteps : int</p>
<blockquote>
<div>max learning steps before ending MCH</div></blockquote>
<dl class="docutils">
<dt>eta</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float,1</span><dd>factor for changing dlamda</dd>
</dl>
<p>estimatedConstraints : ndarray</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MCH.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>initial_guess=None</em>, <em>constraints=None</em>, <em>X=None</em>, <em>tol=None</em>, <em>tolNorm=None</em>, <em>n_iters=30</em>, <em>burnin=30</em>, <em>maxiter=10</em>, <em>custom_convergence_f=None</em>, <em>disp=False</em>, <em>full_output=False</em>, <em>learn_params_kwargs={'eta': 1</em>, <em>'maxdlamda': 1}</em>, <em>generate_kwargs={}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCH.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve for maxent model parameters using MCH routine.</p>
<dl class="docutils">
<dt>initial_guess</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray,None</span><dd>Initial starting point</dd>
</dl>
<p>constraints : ndarray,None
X : ndarray,None</p>
<blockquote>
<div>If instead of constraints, you wish to pass the raw data on which to calculate the
constraints using self.calc_observables.</div></blockquote>
<dl class="docutils">
<dt>tol</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float,None</span><dd>Maximum error allowed in any observable.</dd>
<dt>tolNorm</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>Norm error allowed in found solution.</dd>
<dt>n_iters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int,30</span><dd>Number of iterations to make between samples in MCMC sampling.</dd>
<dt>burnin</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int,30</span><dd>Initial burn in from random sample when MC sampling.</dd>
<dt>max_iter</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int,10</span><dd>Max number of iterations of MC sampling and MCH approximation.</dd>
<dt>custom_convergence_f</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">function,None</span><dd><p class="first">Function for determining convergence criterion. At each iteration, this function should
return the next set of learn_params_kwargs and optionally the sample size.</p>
<p>As an example:
def learn_settings(i):</p>
<blockquote class="last">
<div><p>&#8216;&#8217;&#8217;
Take in the iteration counter and set the maximum change allowed in any given 
parameter (maxdlamda) and the multiplicative factor eta, where 
d(parameter) = (error in observable) * eta.</p>
<p>Additional option is to also return the sample size for that step by returning a 
tuple. Larger sample sizes are necessary for higher accuracy.
&#8216;&#8217;&#8217;
if i&lt;10:</p>
<blockquote>
<div>return {&#8216;maxdlamda&#8217;:1,&#8217;eta&#8217;:1}</div></blockquote>
<dl class="docutils">
<dt>else:</dt>
<dd>return {&#8216;maxdlamda&#8217;:.05,&#8217;eta&#8217;:.05}</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<p>disp : bool,False
full_output : bool,False</p>
<blockquote>
<div>If True, also return the errflag and error history.</div></blockquote>
<p>learn_parameters_kwargs : dict,{&#8216;maxdlamda&#8217;:1,&#8217;eta&#8217;:1}
generate_kwargs : dict,{}</p>
<dl class="docutils">
<dt>parameters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>Found solution to inverse problem.</dd>
<dt>errflag</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>0, converged within given criterion
1, max iterations reached</dd>
<dt>errors</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>Log of errors in matching constraints at each step of iteration.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.MCHIncompleteData">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">MCHIncompleteData</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.MCH" title="coniii.solvers.MCH"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.MCH</span></code></a></p>
<p>Class for solving maxent problems using the Monte Carlo Histogram method on
incomplete data where some spins may not be visible.</p>
<p>Broderick, T., Dudik, M., Tkacik, G., Schapire, R. E. &amp; Bialek, W. Faster
solutions of the inverse pairwise Ising problem. arXiv 1-8 (2007).</p>
<dl class="docutils">
<dt>NOTE: This only works for Ising model.</dt>
<dd>Not ready for release.</dd>
</dl>
<dl class="method">
<dt id="coniii.solvers.MCHIncompleteData.generate_samples">
<code class="descname">generate_samples</code><span class="sig-paren">(</span><em>n_iters</em>, <em>burnin</em>, <em>uIncompleteStates=None</em>, <em>f_cond_sample_size=None</em>, <em>f_cond_sample_iters=None</em>, <em>sample_size=None</em>, <em>sample_method=None</em>, <em>initial_sample=None</em>, <em>run_regular_sampler=True</em>, <em>run_cond_sampler=True</em>, <em>disp=0</em>, <em>generate_kwargs={}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.generate_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around generate_samples_parallel() from available samplers.</p>
<p>n_iters : int
burnin : int</p>
<blockquote>
<div>I think burn in is handled automatically in REMC.</div></blockquote>
<p>uIncompleteStates : list of unique states
f_cond_sample_size : lambda function</p>
<blockquote>
<div>Given the number of hidden spins, return the number of samples to take.</div></blockquote>
<dl class="docutils">
<dt>f_cond_sample_iters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">lambda function</span><dd>Given the number of hidden spins, return the number of MC iterations to make.</dd>
</dl>
<p>sample_size : int
sample_method : str
initial_sample : ndarray
generate_kwargs : dict</p>
<p>None</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MCHIncompleteData.learn_parameters_mch">
<code class="descname">learn_parameters_mch</code><span class="sig-paren">(</span><em>estConstraints</em>, <em>fullFraction</em>, <em>uIncompleteStates</em>, <em>uIncompleteStatesCount</em>, <em>maxdlamda=1</em>, <em>maxdlamdaNorm=1</em>, <em>maxLearningSteps=50</em>, <em>eta=1</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.learn_parameters_mch" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters with MCH step. Update is proportional to the difference between the
observables and the predicted observables after a small change to the parameters. This is
calculated from likelihood maximization, and for the incomplete data points this corresponds
to the marginal probability distribution weighted with the number of corresponding data
points.</p>
<p>estConstraints : ndarray
fullFraction : float</p>
<blockquote>
<div>Fraction of data points that are complete.</div></blockquote>
<dl class="docutils">
<dt>uIncompleteStates</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list-like</span><dd>Unique incomplete states in data.</dd>
<dt>uIncompleteStatesCount</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list-like</span><dd>Frequency of each unique data point.</dd>
</dl>
<p>maxdlamda : float,1
maxdlamdaNorm : float,1
maxLearningSteps : int</p>
<blockquote>
<div>max learning steps before ending MCH</div></blockquote>
<dl class="docutils">
<dt>eta</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float,1</span><dd>factor for changing dlamda</dd>
</dl>
<p>estimatedConstraints : ndarray</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MCHIncompleteData.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>X=None</em>, <em>constraints=None</em>, <em>initial_guess=None</em>, <em>cond_sample_size=100</em>, <em>cond_sample_iters=100</em>, <em>tol=None</em>, <em>tolNorm=None</em>, <em>n_iters=30</em>, <em>burnin=30</em>, <em>maxiter=10</em>, <em>disp=False</em>, <em>full_output=False</em>, <em>learn_params_kwargs={}</em>, <em>generate_kwargs={}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MCHIncompleteData.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Solve for parameters using MCH routine.</p>
<p>X                       : ndarray
constraints             : ndarray</p>
<blockquote>
<div>Constraints calculated from the incomplete data (accounting for missing data points).</div></blockquote>
<dl class="docutils">
<dt>initial_guess</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray=None</span><dd>initial starting point</dd>
<dt>cond_sample_size</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int or function</span><dd>Number of samples to make for conditional distribution.
If function is passed in, it will be passed number of missing spins and must return an int.</dd>
<dt>cond_sample_iters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int or function</span><dd>Number of MC iterations to make between samples.</dd>
<dt>tol</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float=None</span><dd>maximum error allowed in any observable</dd>
<dt>tolNorm</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>norm error allowed in found solution</dd>
<dt>n_iters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int=30</span><dd>Number of iterations to make between samples in MCMC sampling.</dd>
</dl>
<p>burnin (int=30)
disp                    : int=0</p>
<blockquote>
<div>0, no output
1, some detail
2, most detail</div></blockquote>
<dl class="docutils">
<dt>full_output</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,False</span><dd>Return errflag and errors at each iteration if True.</dd>
</dl>
<p>learn_parameters_kwargs : dict
generate_kwargs         : dict</p>
<dl class="docutils">
<dt>parameters</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>Found solution.</dd>
</dl>
<p>errflag : int
errors : ndarray</p>
<blockquote>
<div>Errors in matching constraints at each step of iteration.</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.MPF">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">MPF</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<dl class="method">
<dt id="coniii.solvers.MPF.K">
<code class="descname">K</code><span class="sig-paren">(</span><em>Xuniq</em>, <em>Xcount</em>, <em>adjacentStates</em>, <em>params</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.K" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute objective function.</p>
<dl class="docutils">
<dt>Xuniq</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>(ndata x ndims)
unique states that appear in the data</dd>
<dt>Xcount</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of int</span><dd>number of times that each unique state appears in the data</dd>
<dt>adjacentStates</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list of ndarray</span><dd>list of adjacent states for each given unique state</dd>
<dt>params</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>parameters for computation of energy</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MPF.logK">
<code class="descname">logK</code><span class="sig-paren">(</span><em>Xuniq</em>, <em>Xcount</em>, <em>adjacentStates</em>, <em>params</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.logK" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute log of objective function.</p>
<dl class="docutils">
<dt>Xuniq</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>(n_samples, n_dim)
unique states that appear in the data</dd>
<dt>Xcount</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray of int</span><dd>number of times that each unique state appears in the data</dd>
<dt>adjacentStates</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">list of ndarray</span><dd>list of adjacent states for each given unique state</dd>
<dt>params</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>parameters for computation of energy</dd>
</dl>
<p>logK : float</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.MPF.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>X=None</em>, <em>initial_guess=None</em>, <em>method='L-BFGS-B'</em>, <em>all_connected=True</em>, <em>parameter_limits=100</em>, <em>solver_kwargs={'disp': True</em>, <em>'ftol': 1e-15</em>, <em>'maxiter': 100}</em>, <em>uselog=True</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimize MPF objective function using scipy.optimize.minimize.</p>
<dl class="docutils">
<dt>X</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>(ndata, ndim)
array of states compatible with given energy and adjacent neighbors functions</dd>
<dt>adj</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">lambda state</span><dd>returns adjacent states for any given state</dd>
<dt>all_connected</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,True</span><dd>switch for summing over all states that data sets could be connected to or just summing over
non-data states (second summation in Eq 10 in Sohl-Dickstein 2011)</dd>
<dt>iterate</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int,0</span><dd>number of times to try new initial conditions if first try doesn&#8217;t work. Right now, this is a
pretty coarse test because the fit can be good even without converging.</dd>
<dt>parameter_limits</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">float</span><dd>some limit to constrain the space that the solver has to search. This is the maximum allowed
magnitude of any single parameter.</dd>
<dt>solver_kwargs</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">dict</span><dd>For scipy.optimize.minimize.</dd>
</dl>
<dl class="docutils">
<dt>soln</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>found solution to problem</dd>
<dt>output</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">dict</span><dd>full output from minimize solver</dd>
</dl>
</dd></dl>

<dl class="staticmethod">
<dt id="coniii.solvers.MPF.worker_objective_task">
<em class="property">static </em><code class="descname">worker_objective_task</code><span class="sig-paren">(</span><em>s</em>, <em>Xcount</em>, <em>adjacentStates</em>, <em>params</em>, <em>calc_e</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.MPF.worker_objective_task" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.Pseudo">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">Pseudo</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Pseudolikelihood approximation to solving the inverse Ising problem as described in Aurell
and Ekeberg, PRL 108, 090201 (2012).</p>
<p>solve
_solve
cond_log_likelihood
cond_jac
cond_hess</p>
<dl class="method">
<dt id="coniii.solvers.Pseudo.cond_hess">
<code class="descname">cond_hess</code><span class="sig-paren">(</span><em>r</em>, <em>X</em>, <em>Jr</em>, <em>pairCoocRhat=None</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_hess" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns d^2 cond_log_likelihood / d Jri d Jrj, with shape
(dimension of system)x(dimension of system)</p>
<p>Current implementation uses more memory for speed.
For large sample size, it may make sense to break up differently
if too much memory is being used.</p>
<dl class="docutils">
<dt>pairCooc</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray,None</span><dd>Pass pair_cooc_mat(X) to speed calculation.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Pseudo.cond_jac">
<code class="descname">cond_jac</code><span class="sig-paren">(</span><em>r</em>, <em>X</em>, <em>Jr</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_jac" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns d cond_log_likelihood / d Jr,
with shape (dimension of system)</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Pseudo.cond_log_likelihood">
<code class="descname">cond_log_likelihood</code><span class="sig-paren">(</span><em>r</em>, <em>X</em>, <em>Jr</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.cond_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Equals the conditional log likelihood -L_r.</p>
<dl class="docutils">
<dt>r</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">int</span><dd>individual index</dd>
<dt>X</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>binary matrix, (# X) x (dimension of system)</dd>
<dt>Jr</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>(dimension of system) x (1)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Pseudo.pair_cooc_mat">
<code class="descname">pair_cooc_mat</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.pair_cooc_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns matrix of shape (self.n)x(# X)x(self.n).</p>
<p>For use with cond_hess.</p>
<p>Slow because I haven&#8217;t thought of a better way of doing it yet.</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Pseudo.pseudo_log_likelhood">
<code class="descname">pseudo_log_likelhood</code><span class="sig-paren">(</span><em>X</em>, <em>J</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.pseudo_log_likelhood" title="Permalink to this definition">¶</a></dt>
<dd><p>(Could probably be made more efficient.)</p>
<dl class="docutils">
<dt>X</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>binary matrix, (# of samples) x (dimension of system)</dd>
<dt>J</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>(dimension of system) x (dimension of system)
J should be symmetric</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Pseudo.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Pseudo.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Two different methods are implemented and can be called from self.solve. One is specific to
the Ising model and the other uses a general all-purpose optimization (scipy.optimize) to
solve the problem.</p>
<dl class="docutils">
<dt>general_case</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">bool,True</span><dd>If True, uses self.calc_observables_r and self.get_multipliers_r to maximize the
resulting pseudolikelihood (self._solve_general). Else an algorithm specific to the Ising model is
implemented (self._solve_ising).</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.RegularizedMeanField">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">RegularizedMeanField</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#coniii.solvers.Solver" title="coniii.solvers.Solver"><code class="xref py py-class docutils literal"><span class="pre">coniii.solvers.Solver</span></code></a></p>
<p>Implementation of regularized mean field method for solving the inverse Ising problem, as
described in Daniels, Bryan C., David C. Krakauer, and Jessica C. Flack.  <a href="#id1"><span class="problematic" id="id2">``</span></a>Control of
Finite Critical Behaviour in a Small-Scale Social System.&#8217;&#8217; Nature Communications 8 (2017):
14301.  doi:10.1038/ncomms14301</p>
<p>Specific to pairwise Ising constraints.</p>
<dl class="method">
<dt id="coniii.solvers.RegularizedMeanField.bracket1d">
<code class="descname">bracket1d</code><span class="sig-paren">(</span><em>xList</em>, <em>funcList</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField.bracket1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Assumes xList is monotonically increasing</p>
<p>Get bracketed interval (a,b,c) with a &lt; b &lt; c, and f(b) &lt; f(a) and f(c).
(Choose b and c to make f(b) and f(c) as small as possible.)</p>
<p>If minimum is at one end, raise error.</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.RegularizedMeanField.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><em>samples</em>, <em>numSamples=100000.0</em>, <em>nSkip=None</em>, <em>seed=0</em>, <em>changeSeed=False</em>, <em>numProcs=1</em>, <em>numDataSamples=None</em>, <em>minSize=0</em>, <em>minimizeCovariance=False</em>, <em>minimizeIndependent=True</em>, <em>coocCov=None</em>, <em>priorLmbda=0.0</em>, <em>bracket=None</em>, <em>numGridPoints=200</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.RegularizedMeanField.solve" title="Permalink to this definition">¶</a></dt>
<dd><p>Varies the strength of regularization on the mean field J to best fit given cooccurrence
data.</p>
<dl class="docutils">
<dt>numGridPoints (200)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">If bracket is given, first test at numGridPoints</span><dd>points evenly spaced in the bracket interval, then give
the lowest three points to scipy.optimize.minimize_scalar</dd>
</dl>
<p>numSamples (1e5)            : 
nSkip (None)                :
seed (0)                    :
changeSeed (False)          :
numProcs (1)                :
minSize (0)                 : 3.8.2013 Use a modified model in which</p>
<blockquote>
<div>samples with fewer ones than minSize are not
allowed.</div></blockquote>
<dl class="docutils">
<dt>gradDesc (False)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">5.29.2013 Take a naive gradient descent step</span><dd>after each LM minimization</dd>
<dt>minimizeCovariance (False)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">** As of 7.20.2017, not currently supported **</span><dd>6.3.2013 Minimize covariance from emperical
frequencies (see notes); trying to avoid
biases, as inspired by footnote 12 in 
TkaSchBer06</dd>
<dt>minimizeIndependent (True)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">** As of 7.20.2017, minimizeIndependent is </span><dd><blockquote class="first">
<div>the only mode currently supported **</div></blockquote>
<p class="last">2.7.2014 Each &lt;xi&gt; and &lt;xi xj&gt; residual is treated
as independent</p>
</dd>
<dt>coocCov (None)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">** As of 7.20.2017, not currently supported **</span><dd>2.7.2014 Provide a covariance matrix for
residuals.  Should typically be 
coocSampleCovariance(samples).  Only used
if minimizeCovariance and minimizeIndependent
are False.</dd>
<dt>priorLmbda (0.)</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">** As of 7.20.2017, not currently implemented **</span><dd>Strength of noninteracting prior.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="coniii.solvers.Solver">
<em class="property">class </em><code class="descclassname">coniii.solvers.</code><code class="descname">Solver</code><span class="sig-paren">(</span><em>n</em>, <em>calc_de=None</em>, <em>calc_observables=None</em>, <em>calc_observables_multipliers=None</em>, <em>adj=None</em>, <em>multipliers=None</em>, <em>constraints=None</em>, <em>sample_size=None</em>, <em>sample_method=None</em>, <em>mch_approximation=None</em>, <em>n_cpus=None</em>, <em>verbose=False</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for declaring common methods and attributes for inverse maxent algorithms.</p>
<p>constraints : ndarray
calc_e : lambda function</p>
<blockquote>
<div>Takes states and parameters to calculate the energies.</div></blockquote>
<dl class="docutils">
<dt>calc_observables</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">lambda function</span><dd>Calculate observables from given sample of states.
lambda X: Y
where X is of dimensions (n_samples, n_dim)
and Y is of dimensions (n_samples, n_constraints)</dd>
<dt>multipliers</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">ndarray</span><dd>Langrangian multipliers</dd>
</dl>
<p>estimate_jac
generate_samples
setup_sampler
solve</p>
<dl class="method">
<dt id="coniii.solvers.Solver.estimate_jac">
<code class="descname">estimate_jac</code><span class="sig-paren">(</span><em>eps=0.001</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.estimate_jac" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="coniii.solvers.Solver.generate_samples">
<code class="descname">generate_samples</code><span class="sig-paren">(</span><em>n_iters</em>, <em>burnin</em>, <em>multipliers=None</em>, <em>sample_size=None</em>, <em>sample_method=None</em>, <em>initial_sample=None</em>, <em>generate_kwargs={}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.generate_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper around generate_samples_parallel() methods in samplers.</p>
<p>Samples are saved to self.samples.</p>
<p>n_iters : int
burnin : int</p>
<blockquote>
<div>Burn in is handled automatically in REMC.</div></blockquote>
<p>multipliers : ndarray,None
sample_size : int,None
sample_method : str,None
initial_sample : ndarray,None
generate_kwargs : dict,{}</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Solver.setup_sampler">
<code class="descname">setup_sampler</code><span class="sig-paren">(</span><em>sample_method=None</em>, <em>sampler_kwargs={}</em>, <em>optimize_kwargs={}</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.setup_sampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate sampler class object.</p>
<dl class="docutils">
<dt>sample_method</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">str</span><dd>&#8216;ising_metropolis&#8217;, &#8216;metropolis&#8217;</dd>
</dl>
<p>sampler_kwargs : dict
optimize_kwargs : dict</p>
</dd></dl>

<dl class="method">
<dt id="coniii.solvers.Solver.solve">
<code class="descname">solve</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.Solver.solve" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="coniii.solvers.unwrap_self_worker_obj">
<code class="descclassname">coniii.solvers.</code><code class="descname">unwrap_self_worker_obj</code><span class="sig-paren">(</span><em>arg</em>, <em>**kwarg</em><span class="sig-paren">)</span><a class="headerlink" href="#coniii.solvers.unwrap_self_worker_obj" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">Welcome to ConIII&#8217;s documentation!</a></li>
      <li>Next: <a href="coniii.samplers.html" title="next chapter">coniii.samplers module</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/coniii_rst/coniii.solvers.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Edward D. Lee, Bryan C. Daniels.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="../_sources/coniii_rst/coniii.solvers.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>